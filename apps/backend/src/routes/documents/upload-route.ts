import { getProcessingQueue } from '@/queue/processing-queue.js';
import { getPrismaClient } from '@/services/database.js';
import { ChunkerService, EmbeddingService, HashService } from '@/services/index.js';
import { detectFormat, getProcessingLane, validateUpload } from '@/validators/index.js';
import { FastifyInstance } from 'fastify';
import { mkdir, readFile, rm, writeFile } from 'fs/promises';
import path, { basename } from 'path';

const UPLOAD_DIR = process.env.UPLOAD_DIR || '/tmp/uploads';

// NOTE: Queue is lazily initialized to allow env vars to be set first (important for tests)

export async function uploadRoute(fastify: FastifyInstance): Promise<void> {
  fastify.post('/api/documents', async (request, reply) => {
    try {
      console.log('ðŸ“¤ Upload request received');
      
      const data = await request.file();

      if (!data) {
        console.log('âŒ No file in request');
        return reply.status(400).send({
          error: 'NO_FILE',
          message: 'No file uploaded',
        });
      }

      const buffer = await data.toBuffer();
      const filename = data.filename;
      const mimeType = data.mimetype;

      console.log('ðŸ“„ File details:', {
        filename,
        mimeType,
        size: buffer.length,
      });

      // Validate file
      const validation = validateUpload({
        filename,
        mimeType,
        size: buffer.length,
      });

      if (!validation.valid) {
        console.log('âŒ Validation failed:', validation.error);
        return reply.status(400).send({
          error: validation.error!.code,
          message: validation.error!.message,
        });
      }

      // Detect format
      const format = detectFormat({ filename, mimeType });
      if (!format) {
        console.log('âŒ Format detection failed');
        return reply.status(400).send({
          error: 'INVALID_FORMAT',
          message: 'Unable to detect file format',
        });
      }

      console.log('âœ… Format detected:', format);

      // Validate filename for path traversal
      const sanitizedFilename = basename(filename);
      if (sanitizedFilename !== filename || sanitizedFilename.length === 0 || sanitizedFilename.length > 255) {
        console.log('âŒ Invalid filename');
        return reply.status(400).send({
          error: 'INVALID_FILENAME',
          message: 'Filename contains invalid characters or exceeds length limit',
        });
      }

      // Calculate MD5 hash
      console.log('ðŸ” Calculating MD5 hash...');
      const md5Hash = HashService.md5(buffer);
      console.log('âœ… MD5 hash:', md5Hash);

      // Check for duplicates
      console.log('ðŸ” Checking for duplicates...');
      const prisma = getPrismaClient();
      const existing = await prisma.document.findUnique({
        where: { md5Hash },
      });

      if (existing) {
        console.log('âš ï¸ Duplicate file found:', existing.id);
        return reply.status(409).send({
          error: 'DUPLICATE_FILE',
          message: 'File already exists',
          existingId: existing.id,
        });
      }

      // Determine processing lane
      const lane = getProcessingLane(format);
      console.log('ðŸ›£ï¸ Processing lane:', lane);

      // Use MD5 hash only for unique storage (prevents path traversal)
      const filePath = path.join(UPLOAD_DIR, md5Hash);

      // Save file to disk with error handling
      console.log('ðŸ’¾ Saving file to disk:', filePath);
      try {
        await mkdir(UPLOAD_DIR, { recursive: true });
        // Allow overwrite - if MD5 is same, content is identical
        await writeFile(filePath, buffer);
        console.log('âœ… File saved successfully');
      } catch (error: any) {
        console.error('âŒ File save error:', error);
        return reply.status(500).send({
          error: 'STORAGE_ERROR',
          message: `Failed to save file: ${error.message}`,
        });
      }

      // Create document record (with cleanup on failure)
      console.log('ðŸ“ Creating document record...');
      let document;
      try {
        document = await prisma.document.create({
          data: {
            filename: sanitizedFilename,
            mimeType,
            fileSize: buffer.length,
            format,
            lane,
            status: 'PENDING',
            filePath,
            md5Hash,
          },
        });
        console.log('âœ… Document created:', document.id);
      } catch (error) {
        console.error('âŒ Database error:', error);
        // Cleanup file if DB insert fails
        await rm(filePath).catch(console.error);
        throw error;
      }

      // Process based on lane
      if (lane === 'fast') {
        // Fast lane: Process immediately (JSON, TXT, MD)
        console.log('âš¡ Fast lane processing - reading file...');

        try {
          // 1. Read file content
          const fileContent = await readFile(filePath, 'utf-8');
          console.log(`âœ… File read: ${fileContent.length} characters`);

          // 2. Chunk the content
          const chunker = new ChunkerService();
          const { chunks } = await chunker.chunk(fileContent);
          console.log(`âœ… Created ${chunks.length} chunks`);

          // 3. Generate embeddings for all chunks
          const embedder = new EmbeddingService();
          const texts = chunks.map((c) => c.content);
          const embeddings = await embedder.embedBatch(texts);
          console.log(`âœ… Generated ${embeddings.length} embeddings`);

          // 4. Store chunks in database with embeddings
          for (let i = 0; i < chunks.length; i++) {
            const chunk = chunks[i];
            const embedding = embeddings[i];

            await prisma.$executeRaw`
              INSERT INTO chunks (id, document_id, content, chunk_index, embedding, char_start, char_end, heading, created_at)
              VALUES (
                gen_random_uuid(),
                ${document.id},
                ${chunk.content},
                ${chunk.index},
                ${embedding}::vector,
                ${chunk.metadata.charStart},
                ${chunk.metadata.charEnd},
                ${chunk.metadata.heading || null},
                NOW()
              )
            `;
          }
          console.log(`âœ… Stored ${chunks.length} chunks in database`);

          // 5. Update document status to COMPLETED
          await prisma.document.update({
            where: { id: document.id },
            data: { status: 'COMPLETED' },
          });
          console.log('âœ… Document marked as COMPLETED');

        } catch (error) {
          console.error('âŒ Fast lane processing error:', error);
          await prisma.document.update({
            where: { id: document.id },
            data: {
              status: 'FAILED',
              failReason: error instanceof Error ? error.message : 'Processing failed',
            },
          }).catch(console.error);
          throw error;
        }
      } else {
        // Heavy lane: Queue for processing (PDF)
        console.log('ðŸ“¬ Adding to queue...');
        await getProcessingQueue().add('process', {
          documentId: document.id,
          filePath: filePath,
          format: format as any,
          config: {
            ocrMode: 'auto',
            ocrLanguages: ['en'],
          },
        });
        console.log('âœ… Queued successfully');
      }

      console.log('ðŸŽ‰ Upload complete, returning 201');
      return reply.status(201).send({
        id: document.id,
        filename: document.filename,
        status: document.status,
        format: document.format,
        lane: document.lane,
      });
    } catch (error: any) {
      console.error('ðŸ’¥ UPLOAD ROUTE ERROR:', error);
      console.error('Stack trace:', error.stack);

      // Handle Fastify file size limit error
      if (error.code === 'FST_REQ_FILE_TOO_LARGE') {
        return reply.status(413).send({
          error: 'INTERNAL_ERROR',
          message: error.message || 'Request file too large',
        });
      }

      return reply.status(500).send({
        error: 'INTERNAL_ERROR',
        message: error.message || 'Internal server error',
        details: process.env.NODE_ENV === 'development' ? error.stack : undefined,
      });
    }
  });
}
